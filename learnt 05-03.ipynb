{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'display.max_rows = 6 \\nsets the maximum number of rows displayed when printing Pandas DataFrame or Series objects to 6 rows.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup code and import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import matplotlib.pyplot as plt\n",
    "#* from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(12345) \n",
    "plt.rc('figure', figsize=(10, 6)) # adjusts the default figure size for Matplotlib plots\n",
    "np.set_printoptions(precision=4, suppress=True) \n",
    "pd.options.display.max_rows = 6 \n",
    "\n",
    "'''from bs4 import BeautifulSoup \n",
    "imports the BeautifulSoup class from the bs4 module, which is part of the Beautiful Soup library. Beautiful Soup is a Python library used for web scraping and parsing HTML and XML documents.'''\n",
    "\n",
    "'''import re\n",
    "This imports the regular expression module, which provides support for working with regular expressions in Python. Regular expressions are used for pattern matching and string manipulation.'''\n",
    "\n",
    "'''np.random.seed(12345)\n",
    "When you set a random seed, subsequent calls to random number generation functions will produce the same sequence of random numbers.'''\n",
    "\n",
    "'''np.set_printoptions(precision=4, suppress=True) \n",
    "precision=4 sets the precision for floating-point numbers to 4 decimal places \n",
    "\n",
    "suppress=4 suppresses the printing of small floating-point values in scientific notation. When set to True, NumPy will print floating-point numbers in fixed-point notation instead of scientific notation.\n",
    "'''\n",
    "\n",
    "'''display.max_rows = 6 \n",
    "sets the maximum number of rows displayed when printing Pandas DataFrame or Series objects to 6 rows.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religion</th>\n",
       "      <th>&lt;$10k</th>\n",
       "      <th>$10-20k</th>\n",
       "      <th>$20-30k</th>\n",
       "      <th>$30-40k</th>\n",
       "      <th>$40-50k</th>\n",
       "      <th>$50-75k</th>\n",
       "      <th>$75-100k</th>\n",
       "      <th>$100-150k</th>\n",
       "      <th>&gt;150k</th>\n",
       "      <th>Don't know/refused</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agnostic</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>137</td>\n",
       "      <td>122</td>\n",
       "      <td>109</td>\n",
       "      <td>84</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atheist</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buddhist</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>39</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Other Faiths</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>63</td>\n",
       "      <td>46</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Other World Religions</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>217</td>\n",
       "      <td>299</td>\n",
       "      <td>374</td>\n",
       "      <td>365</td>\n",
       "      <td>341</td>\n",
       "      <td>528</td>\n",
       "      <td>407</td>\n",
       "      <td>321</td>\n",
       "      <td>258</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
       "0                Agnostic     27       34       60       81       76      137   \n",
       "1                 Atheist     12       27       37       52       35       70   \n",
       "2                Buddhist     27       21       30       34       33       58   \n",
       "..                    ...    ...      ...      ...      ...      ...      ...   \n",
       "15           Other Faiths     20       33       40       46       49       63   \n",
       "16  Other World Religions      5        2        3        4        2        7   \n",
       "17           Unaffiliated    217      299      374      365      341      528   \n",
       "\n",
       "    $75-100k  $100-150k  >150k  Don't know/refused  \n",
       "0        122        109     84                  96  \n",
       "1         73         59     74                  76  \n",
       "2         62         39     53                  54  \n",
       "..       ...        ...    ...                 ...  \n",
       "15        46         40     41                  71  \n",
       "16         3          4      4                   8  \n",
       "17       407        321    258                 597  \n",
       "\n",
       "[18 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests # The requests library is commonly used for making HTTP requests in Python\n",
    "import io\n",
    "\n",
    "# get data from the website link i.e make a GET request\n",
    "r = requests.get('https://raw.githubusercontent.com/tidyverse/tidyr/master/data-raw/relig_income.csv')\n",
    "\n",
    "print(r) \n",
    "\n",
    "snippet = pd.read_csv(filepath_or_buffer=io.StringIO(r.text))\n",
    "\n",
    "snippet\n",
    "\n",
    "# r.text: This is the attribute of the response object r obtained from the requests.get() method. It contains the text content of the response received from the website. In this case, the text content is assumed to be in CSV format.\n",
    "\n",
    "# io.StringIO() Allows the text content(r.text) to be treated as a file-like object, that can be passed to functions expecting a file-like input\n",
    "\n",
    "#* By using io.StringIO(r.text) as the source for reading the CSV data, we are effectively treating the text content obtained from the HTTP response as if it were a file, allowing us to parse it using pd.read_csv() without having to save it to a physical file first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religion</th>\n",
       "      <th>income</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agnostic</td>\n",
       "      <td>&lt;$10k</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atheist</td>\n",
       "      <td>&lt;$10k</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buddhist</td>\n",
       "      <td>&lt;$10k</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Other Faiths</td>\n",
       "      <td>Don't know/refused</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Other World Religions</td>\n",
       "      <td>Don't know/refused</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Don't know/refused</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  religion              income  count\n",
       "0                 Agnostic               <$10k     27\n",
       "1                  Atheist               <$10k     12\n",
       "2                 Buddhist               <$10k     27\n",
       "..                     ...                 ...    ...\n",
       "177           Other Faiths  Don't know/refused     71\n",
       "178  Other World Religions  Don't know/refused      8\n",
       "179           Unaffiliated  Don't know/refused    597\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(snippet, id_vars='religion', var_name='income', value_name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular expressions\n",
    "\n",
    "| Special Characters | Explanation | Example of matches |\n",
    "| --- | --- | --- |\n",
    "| `.` | This character will match against anything. It is essentially a wild card. By default, Python doesn't include new lines. | The regex `\".a\"` will match the following. `\"aa\"`, `\"Aa\"`, `\"ba\"`, `\"Ba\"`, `\"ca\"`, `\"da\"`, etc. But, it will also match strings like `\"aaa\"`, `\"Aat\"`, `\"taa\"` because the regex is matching for *substrings*.|\n",
    "|`^` | Matches the start of the string. | The regex `\"^s.a\"` will match the following. `\"saa\"`, `\"sAa\"`, `\"sba\"`, `\"sBa\"`, `\"sca\"`, `\"sda\"`, etc. But, it will not match `\"asda\"` because the string starts with `\"a\"`. |\n",
    "| `$` | Matches the end of the string or just before the newline at the end of the string. |The regex `\"$a\"` will match the following. `\"aa\"`, `\"Aa\"`, `\"ba\"`, `\"Ba\"`, `\"ca\"`, `\"da\"`, etc. |\n",
    "| `?` | Matches 0 or 1 occurrences of a string. | The regex `\"columns?\"` will match both `\"column\"` and its plural, `\"columns\"`. |\n",
    "| `*` | Matches 0 or more occurrences of a string. | The regex `\"11*\"` will match `\"1\"` or any consecutive sequences of ones. |\n",
    "| `\\` | Escapes special characters, allowing them to be used for matching. | `\".\"` matches any character, but `\"\\.\"` matches any string containing a period. |\n",
    "| &#124; | Matches either the first or the second character, but not both nor neither. | `\"^a&#124;b$\"` only matches the strings `\"a\"` and `\"b\"`. |\n",
    "|`(...)`| Matches the substring as a whole. | The regex \"(1 &#124; 0)*\" matches any string containing a consecutive binary substring  of the same number or empty string. |\n",
    "| `[...]` | Allows matching only on characters specified.  | `\"[01]*\"` matches all binary strings. The repetition (`*`) doesn't reapply on a fixed matched string but on the pattern. |\n",
    "\n",
    "There are more operators present in the `re` package \\cite{Kuchling2018}, but the above operations are present in almost all packages independent of implementation and programming language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: re.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\meddi\\AppData\\Local\\Temp\\ipykernel_31240\\2879738364.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  wsRegex = re.compile(\"\\s+\") # the plus just means one or more matches. same as '\"\\s\\s*\"'\n",
      "C:\\Users\\meddi\\AppData\\Local\\Temp\\ipykernel_31240\\2879738364.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  wsRegex = re.compile(\"\\s\\s*\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "re.compile(r'\\s\\s*', re.UNICODE)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsRegex = re.compile(\"\\s+\") # The + means one or more matches. same as '\"\\s\\s*\"'\n",
    "\n",
    "wsRegex = re.compile(\"\\s\\s*\")\n",
    "# This string does not use a raw string literal or escape sequences for the backslash. \\s represents a whitespace character, and \\s* represents zero or more whitespace characters.\n",
    "\n",
    "wsRegex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' \\s is a special sequence in regular expressions, not in Python string literals. It represents a whitespace character (such as spaces, tabs, and newlines). To avoid this warning, you can either use a raw string literal by prefixing the string with r, which tells Python not to interpret backslashes as escape characters, or you can double the backslashes to escape them properly within the regular expression pattern.'''\n",
    "\n",
    "'''re.compile(\"\\s+\") returns a regular expression object compiled from the pattern \"\\s+\", which matches one or more whitespace characters. This compiled regular expression object can then be used to perform various operations such as searching, matching, and replacing text based on the defined pattern.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'\\s+', re.UNICODE)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsRegex = re.compile(r\"\\s+\") # raw string literal r\"\\s+\" treats backslashes as literal characters\n",
    "\n",
    "wsRegex = re.compile(\"\\\\s+\") # \\\\ is needed to represent a single backslash \\\n",
    "\n",
    "wsRegex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Hello,', 'World,', 'How', 'are', 'you,', 'today?', '']\n",
      "['', 'Hello,', 'World,', 'How', 'are', 'you,', 'today?', '']\n",
      "['Hello,', 'World,', 'How', 'are', 'you,', 'today?']\n",
      "['', '', '', 'Hello,', 'World,', 'How', 'are', 'you,', 'today?', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "x = \"   Hello, World, How are you, today?   \"\n",
    "\n",
    "print(wsRegex.split(x)) # separates on substring matches\n",
    "\n",
    "# An alternative is to call re.split('\\s+', x), where the regular expression is first compiled, then split() is called on the passed text. In our example we chose to compile the regex with re.compile('\\s+'), which returns a reusable regex object for faster matching throughput. As such, creating a regex object with re.compile is highly recommended. When applying the same expression on many strings, CPU cycles will be saved from the compilation.\n",
    "\n",
    "#* Using a pre-compiled regular expression object is more efficient\n",
    "\n",
    "print(re.split('\\\\s+', x))\n",
    "\n",
    "print(x.split()) # discard empty strings from the result\n",
    "\n",
    "print(x.split(' ')) # separates on character matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: re.findall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o']\n",
      "['o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'oo', 'oo', 'oo']\n",
      "['o', 'O', 'o', 'o', 'O', 'o', 'O', 'O', 'o', 'o', 'O', 'o', 'O', 'o', 'o', 'O', 'O', 'O', 'O', 'o', 'o', 'o', 'O', 'o', 'o', 'o', 'o', 'O']\n",
      "['oOo', 'oOoO', 'O', 'o', 'o', 'OoOo', 'o', 'OO', 'OOo', 'oo', 'Ooo', 'ooO']\n"
     ]
    }
   ],
   "source": [
    "x = \"IoOo00oOoO0OioIolOoOoiolOO1OOoloo|Ooo0IiooO|1\"\n",
    "\n",
    "rex1 = re.compile('o')\n",
    "\n",
    "rex2 = re.compile('o+') # matches one or more occurrences of the letter 'o' consecutively\n",
    "\n",
    "rex3 = re.compile('[oO]') \n",
    "\n",
    "rex4 = re.compile('[oO]+') # I think: 'o' or 'O' occurrences, consecutive or non consecutively\n",
    "\n",
    "# re.findall() # Return a list of all non-overlapping matches in the string.\n",
    "\n",
    "print(rex1.findall(x))\n",
    "\n",
    "print(rex2.findall(x)) \n",
    "\n",
    "print(rex3.findall(x))\n",
    "\n",
    "print(rex4.findall(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: The span() method\n",
    "\n",
    "The span() method(found in the re module) returns a tuple containing the start and end positions of the match. This method is typically used after performing a match using functions like match(), search(), or findall() from the re module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 4), match='oOo'>\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "rex4 = re.compile('[oO]+')\n",
    "\n",
    "z = rex4.search(x) # Returns the first match and the index of the start and end of that match\n",
    "\n",
    "print(z)\n",
    "\n",
    "print(z.span()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: re.sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I , 000 , i , II , li , l1l1| , 0Ii|1'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"IoOo000OioIIoliol1l1|oo0Ii|1\"\n",
    "\n",
    "rex4 = re.compile('[oO]+')\n",
    "\n",
    "# sub() replaces every occurrence of a pattern with a string or the result of a function\n",
    "rex4.sub(string=x, repl=' , ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtyDF = pd.read_csv(filepath_or_buffer= 'examples/ex4.csv', \n",
    "                      names=['message','a', 'b', 'c', 'd'],\n",
    "                      index_col='message')\n",
    "\n",
    "dirtyDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedDF = pd.read_csv(filepath_or_buffer = 'examples/ex4.csv',\n",
    "                  engine='python',\n",
    "                  sep=',',\n",
    "                  header=0, # lines containing headers.\n",
    "                  # Sometimes they can be on multiple lines due to formatting (numbering starts from 0)\n",
    "                  names=['message', 'a', 'b', 'c', 'd'], # the names we want to use to index columns\n",
    "                  index_col=['message'], \n",
    "                  skiprows=[0,2,3,6, 7],  # we don't skip any rows, just comments.\n",
    "                                          # But useful when columns and data separated by whitespace or metadata,\n",
    "                                          # such as line or page breaks'''\n",
    "                  skipfooter=3,\n",
    "                  na_values={'a': ['NaN'],\n",
    "                             'b': ['NaN'],\n",
    "                             'c': ['NaN'],\n",
    "                             'd': ['NaN'],\n",
    "                             'message': ['NA']} '''what values from the columns are actually considered NA or NaN\n",
    "                                                   by pandas DataFrames.'''\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedDF.dropna() # Remove missing values.\n",
    "cleanedDF.fillna() # Fill NA/NaN values using the specified method.\n",
    "cleanedDF.notnull() # Detect existing (non-missing) values. Return a boolean same-sized object indicating if the values are not NA.'''\n",
    "\n",
    "cleanedDF['C'] = cleanedDF['c'].fillna(cleanedDF['c'].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_excel(\"examples/random.numbers.xlsx\", index_col=[0])\n",
    "\n",
    "pd.concat([df6, df6], axis=0, keys=['f', 's']) \n",
    "\n",
    "'''keys=['f', 's'] \n",
    "Assigns the keys 'f' and 's' to the resulting concatenated DataFrames, which will be used to label the multi-level columns.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation \n",
    "\n",
    "Imputation is the act of filling missing values with substituted values. However, it usually refers to filling missing data with representative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly ordering\n",
    "x = df6.sample(frac=1, replace=False)\n",
    "y = df6.sample(frac=1, replace=False)\n",
    "\n",
    "j1 = x.merge(y, left_index=True, right_index=True, suffixes=('_x', '_y'), sort=True)\n",
    "\n",
    "'''\n",
    "left_index : bool, default False\n",
    "    Use the index from the left DataFrame as the join key(s). \n",
    "\n",
    "suffixes : list-like, default is (\"_x\", \"_y\")\n",
    "    A length-2 sequence where each element is optionally a string indicating the suffix to add to overlapping column names in left and right respectively.   \n",
    "\n",
    "    sort : bool, default False\n",
    "    Sort the join keys lexicographically in the result DataFrame. If False, the order of the join keys depends on the join type (how keyword).  \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'k1': ['one', 'two'] * 14,\n",
    "                     'k2': [0, 1, 0, 1, 1,\n",
    "                            1, 0, 3, 1, 1,\n",
    "                            0, 1, 3, 2, 1,\n",
    "                            1, 0, 1, 1, 1,\n",
    "                            3, 1, 2, 2, 1,\n",
    "                            1, 0, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated() # Return boolean Series denoting (fully)duplicate rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset='k2') # specify a column to drop duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ounces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacon</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pulled pork</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacon</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>honey ham</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nova lox</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           food  ounces\n",
       "0         bacon     4.0\n",
       "1   pulled pork     3.0\n",
       "2         bacon    12.0\n",
       "..          ...     ...\n",
       "6      pastrami     3.0\n",
       "7     honey ham     5.0\n",
       "8      nova lox     6.0\n",
       "\n",
       "[9 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',\n",
    "                              'Pastrami', 'corned beef', 'Bacon',\n",
    "                              'pastrami', 'honey ham', 'nova lox'],\n",
    "                     'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ounces</th>\n",
       "      <th>grams</th>\n",
       "      <th>animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.3980</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pulled pork</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0485</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacon</td>\n",
       "      <td>12.0</td>\n",
       "      <td>340.1940</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0485</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>honey ham</td>\n",
       "      <td>5.0</td>\n",
       "      <td>141.7475</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nova lox</td>\n",
       "      <td>6.0</td>\n",
       "      <td>170.0970</td>\n",
       "      <td>salmon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           food  ounces     grams  animal\n",
       "0         bacon     4.0  113.3980     pig\n",
       "1   pulled pork     3.0   85.0485     pig\n",
       "2         bacon    12.0  340.1940     pig\n",
       "..          ...     ...       ...     ...\n",
       "6      pastrami     3.0   85.0485     cow\n",
       "7     honey ham     5.0  141.7475     pig\n",
       "8      nova lox     6.0  170.0970  salmon\n",
       "\n",
       "[9 rows x 4 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meat_to_animal = {\n",
    "  'bacon': 'pig',\n",
    "  'pulled pork': 'pig',\n",
    "  'pastrami': 'cow',\n",
    "  'corned beef': 'cow',\n",
    "  'honey ham': 'pig',\n",
    "  'nova lox': 'salmon'\n",
    "}\n",
    "\n",
    "data['grams'] = data['ounces'].map(lambda x: x*28.3495)\n",
    "\n",
    "# map each food to the corresponding animal in the meat_to_animal dictionary\n",
    "data['animal'] = data['food'].str.lower().map(meat_to_animal) \n",
    "\n",
    "# Converting all the strings in the 'food' columns to lowercase is done to ensure consistency because the keys in the meat_to_animal dictionary are all lowercase.\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113.3980\n",
       "1     85.0485\n",
       "2    340.1940\n",
       "       ...   \n",
       "6     85.0485\n",
       "7    141.7475\n",
       "8    170.0970\n",
       "Name: ounces, Length: 9, dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ounces'].map(lambda x : x*28.3495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fillna( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'examples/ex1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[164], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df4 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexamples/ex1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# lines containing headers.\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# Sometimes they can be on multiple lines due to formatting (numbering starts from 0)\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# the names we want to use to index columns\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# what is indexing the columns?\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                  \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# we don't skip any rows, only comments.\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# But this is useful when columns and data separated by whitespace or metadata.\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# Or if page breaks are in the data.\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                  \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# we grab all the rows\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                  \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# what values from the files are actually not available or not expressible\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfoo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aiga\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1012\u001b[0m     dialect,\n\u001b[0;32m   1013\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aiga\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Aiga\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aiga\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Aiga\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'examples/ex1.csv'"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(filepath_or_buffer = 'examples/ex1.csv',\n",
    "                  sep=',',\n",
    "                  # lines containing headers.\n",
    "                  # Sometimes they can be on multiple lines due to formatting (numbering starts from 0)\n",
    "                  header=0, \n",
    "\n",
    "                  # the names we want to use to index columns\n",
    "                  names=['a', 'b', 'c', 'd', 'message'], \n",
    "\n",
    "                  # what is indexing the columns?\n",
    "                  index_col='message', \n",
    "                  \n",
    "                  # we don't skip any rows, only comments.\n",
    "                  # But this is useful when columns and data separated by whitespace or metadata.\n",
    "                  # Or if page breaks are in the data.\n",
    "                  skiprows=0, \n",
    "                  \n",
    "                   # we grab all the rows\n",
    "                  nrows=3,\n",
    "                  \n",
    "                  # what values from the files are actually not available or not expressible\n",
    "                  na_values={'message': ['foo', 'NA'], 'a': ['1'], 'b': ['1'], 'c': ['1'], 'd': ['1']} \n",
    "                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
